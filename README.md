# Welcome Friends!
<p>To my github portfolio! Here I will showcase a few of the projects I have worked on. At current most of the projects showcased are Data Science and Analysis, mostly done in python. While python is currently my prefered language, I have also worked in Java, C++, and to a lesser extent Javascript. One of the main reasons I love Python is due to it's lightning fast development, and it's intense evolution of libraries. </p>

## Projects
<div>
  <a href='https://github.com/CharlesPizza/HeartFailure'><strong>Heart Failure Prediction</strong></a>
  <p>Here we do random forest modeling to predict death events following hospital admissions. Using exploritory data analysis we attempt to identify relevant features and disprove them. We do this with and without time components due to the problems inherit with time analysis and monitoring periods. <br>
    Libraries: sklearn, pandas, numpy, seaborn, plotly, matplotlib
  </p>
</div>

<div>
  <a href='https://github.com/CharlesPizza/BoxOfficeMovies'><strong>Data Collection</strong></a>
  <p>In this project we utilize several webscrapping libraries inorder to build an application to aggregate data across several affiliated websites which have a secure API and flex script impeding more robotic access. <br>
  Libraries: bs4, selenium, re, requests, pandas, numpy, lxml</p>
</div>

<div>
  <a href='https://www.github.com/CharlesPizza/'><strong>Movie Recommendation System</strong></a>
  <p>Here we create a recommendation system using a CSR Matrix and a KNNeighbors (Euclidean Distance) Algorthym. The recommendations are item based and segregated by genres. We've created only a small filesystem of images, so the interface reflects only this subsection, however it is ready to be easily converted to the entire movie library as all functions are the same. <br>
  Libraries: pyarrow, numpy, pandas, scipy, sklearn, </p>
</div>

<div>
  <a href='https://github.com/CharlesPizza/Data-Restructure-for-Performance'><strong>Data Restructure for Memory Handling and Optimization</strong></a>
  <p>Restructuring a 16gb dataset to work in Kaggle's memory strained environment. We change csv to parquet, we convert strings to int16, floats to int8 for categorical representation, and use multiprocessing to avoid the free list phenomenon and allow Kaggle to reallocate the memory of the 16gb dataset.<br>
  Libraries: pyarrow, pandas, numpy, multiprocessing, resource, sys, gc </p>
</div>



<!--
**CharlesPizza/CharlesPizza** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- âš¡ Fun fact: ...
-->
